{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aec42ab5",
   "metadata": {},
   "source": [
    "# Course work\n",
    "\n",
    "\n",
    "1. Get the data - run the cell below this to get your data\n",
    "\n",
    "2. Read in the csv:\n",
    "```\n",
    "df = pd.read_csv('coursework-data.csv')\n",
    "```\n",
    "3. Perform some exploratory data analysis to clean up the dataset. The code needed for this part is found in the first set of exercises that you did. \n",
    "    - Remove outliers\n",
    "    - If any pairs of variables are highly correlated, remove one of the pair - highly correlated in this case > 0.99\n",
    "\n",
    "4. Fit a baseline model, linear regression to map the control parameters (all parameters *except* `gllbsc_gap`) to the dependent parameter `gllbsc_gap`. Summarise its performance. \n",
    "\n",
    "To set up the data use:\n",
    "```\n",
    "x = training_data.loc[:, training_data.columns != \"gllbsc_gap\"].values\n",
    "y = training_data.loc[:, training_data.columns == \"gllbsc_gap\"].values\n",
    "```\n",
    "The rest of the code you need for this found in the second set of exercises that you did. \n",
    "\n",
    "- From looking at the linear regression model, which features have the greatest influence on the band gap?\n",
    "\n",
    "\n",
    "5. Develop a gradient boosted regressor to the same data. Summarise its performance.\n",
    "\n",
    "## <span style=\"color:red\"> Important notes</span>\n",
    "\n",
    "### Saving coursework\n",
    "\n",
    "* If you want to save and reload the notebooks you will need to save a copy of the original notebook to your _Google Drive_\n",
    "* Go to File > Save copy in Drive\n",
    "* When you want to reload navigate to: http://colab.research.google.com/\n",
    "* Got to File > Open\n",
    "* Choose the _Google Drive_ tab, you should now see your saved notebooks.\n",
    "\n",
    "### Submitting the coursework\n",
    "\n",
    "When you are finished with the coursework - use `File > Print > Save as pdf` to download a pdf of the completed notebook. Submit this pdf _via_ the portal on QMplus. \n",
    "\n",
    "<span style=\"color:red\"> The deadline for submission is Friday 28th April at 16:00.</span>\n",
    "\n",
    "### Text explanations\n",
    "\n",
    "**Please please please** add text to explain what you are doing in the code. Adding text boxes is easy, just add a new cell as normal then change the type to `Markdown` with the dropdown menu at the top of the cells. Adding text will make sure that markers can give you proper grades even if you make a small slip in your code. If you have no text explanation and still have a small slip, you will likely get no marks!\n",
    "\n",
    "### Datasets\n",
    "\n",
    "All of your datasets are generated randomly. So do not expect the same answers as your friends. If you compare answers and find that you have something very different, do not worry.\n",
    "\n",
    "### Warnings from the code\n",
    "\n",
    "Don't worry if the code throws some warnings sometimes. If it keeps running then it is fine. Warnings usually just alert you to future planned changes in the code you are using.\n",
    "\n",
    "### Long run times\n",
    "\n",
    "There is a certain part of the exercise where a grid search is required. It could take quite a long time with this code. I have tested it and it took about 15 minutes for a 10-fold cross validation on a 5x5 gridsearch. Dont worry if it seems to be running for a long time, that's okay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e2a037e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-04 12:30:08--  https://zenodo.org/record/7798373/files/base-data.csv\n",
      "Resolving zenodo.org (zenodo.org)... 188.185.124.72\n",
      "Connecting to zenodo.org (zenodo.org)|188.185.124.72|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 149050 (146K) [text/plain]\n",
      "Saving to: ‘base-data.csv.2’\n",
      "\n",
      "base-data.csv.2     100%[===================>] 145.56K   636KB/s    in 0.2s    \n",
      "\n",
      "2023-04-04 12:30:09 (636 KB/s) - ‘base-data.csv.2’ saved [149050/149050]\n",
      "\n",
      "File already exists no more to see here.\n"
     ]
    }
   ],
   "source": [
    "!wget https://zenodo.org/record/7798373/files/base-data.csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from os.path import exists\n",
    "\n",
    "NUM_OUTLIERS = 3\n",
    "OUTLIER_VALUE = 1e5\n",
    "NUM_DUPS = 2\n",
    "newnames = ['LUMO values', 'Periodic nature']\n",
    "#wget the data\n",
    "orig_data = pd.read_csv('base-data.csv')\n",
    "\n",
    "if exists('coursework-data.csv'):\n",
    "    print('File already exists no more to see here.')\n",
    "else:\n",
    "    change = orig_data.sample(NUM_OUTLIERS).index\n",
    "    cols = random.sample(range(0, 12), NUM_OUTLIERS)\n",
    "    for j, i in enumerate(change):\n",
    "        n = cols[j]\n",
    "        name = orig_data.columns[n]\n",
    "        orig_data.loc[i, name] = OUTLIER_VALUE\n",
    "\n",
    "## Duplicate two random columns\n",
    "    names = orig_data.columns\n",
    "\n",
    "    for i in range(NUM_DUPS):\n",
    "        index = np.random.randint(0, len(names)-1)\n",
    "        n = names[index]\n",
    "        orig_data[newnames[i]] = orig_data.loc[:, n]\n",
    "\n",
    "    orig_data = orig_data.sample(frac=1, axis=1)\n",
    "\n",
    "## This is for my data to clean up the names\n",
    "    orig_data = orig_data.rename(columns={'MagpieData avg_dev Number' : 'Number dev',  'MagpieData avg_dev AtomicWeight' : 'Weight dev', 'MagpieData mean NValence' : 'NValence mean', 'MagpieData avg_dev MeltingT': 'MeltT dev', 'MagpieData mean MeltingT': 'MeltT mean', 'MagpieData avg_dev CovalentRadius': 'CovRad dev', 'MagpieData avg_dev SpaceGroupNumber': 'Spg dev','MagpieData avg_dev GSvolume_pa': 'GS dev', 'MagpieData mean GSvolume_pa': 'GS mean', 'MagpieData avg_dev NdValence': 'NdValence dev', 'MagpieData avg_dev MendeleevNumber': 'Mendeleev dev', 'MagpieData avg_dev Electronegativity': 'Eneg dev'})\n",
    "\n",
    "    orig_data.to_csv('coursework-data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e0156d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
