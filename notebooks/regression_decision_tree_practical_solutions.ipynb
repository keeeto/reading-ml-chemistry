{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kgdl-FKasIAJ"
      },
      "source": [
        "# Regression using Decision Trees\n",
        "\n",
        "In this notebook, we will use decision trees to solve regression problems. \n",
        "\n",
        "The dataset used here originates from a project to build a surrogate model for predicting the band gap of a material from its composition. This surrogate model was used to replace expensive qunatum mecahnical calculations in virtual high-throughput screening of materials for application as photocatalysts. The paper was published in [Chemistry of Materials](https://pubs.acs.org/doi/abs/10.1021/acs.chemmater.9b01519). \n",
        "\n",
        "![image.png](attachment:image.png)\n",
        "\n",
        "Through this pracitcal, we will learn not only the usage of regression trees but, more importantly, how to tune hyperparameters for best performance.\n",
        "\n",
        "## Set up the Python environment\n",
        "\n",
        "Run the cell below to import the various packages that we will use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9R3-Lr27sIAL"
      },
      "outputs": [],
      "source": [
        "# sklearn\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import sklearn.datasets\n",
        "\n",
        "# helpers\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol8SyPPfsIAM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXACsEO5sIAN"
      },
      "source": [
        "# The Dataset\n",
        "\n",
        "We initially download the data from `zenodo`. The data repo is [here](https://zenodo.org/record/4450207).\n",
        "\n",
        "Our data are stored in the pickle file `./training_data.pickle`. We load this file into a `pandas.DataFrame` object, an efficient interface to manage column-wise, heterogeneous tabular data. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_cEf6GYsIAN",
        "outputId": "bc8e635f-7516-48f8-fac7-6aa300ddaa74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2021-02-02 10:19:15--  https://zenodo.org/record/4450207/files/training_data.pickle\n",
            "Resolving zenodo.org (zenodo.org)... 137.138.76.77\n",
            "Connecting to zenodo.org (zenodo.org)|137.138.76.77|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 900335 (879K) [application/octet-stream]\n",
            "Saving to: ‘training_data.pickle’\n",
            "\n",
            "training_data.pickl 100%[===================>] 879.23K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-02-02 10:19:15 (7.96 MB/s) - ‘training_data.pickle’ saved [900335/900335]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://zenodo.org/record/4450207/files/training_data.pickle\n",
        "oxides = pd.read_pickle('./training_data.pickle')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8yBf0MQsIAP"
      },
      "source": [
        "We can check all the columns presented in the dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "bSGag67usIAQ"
      },
      "outputs": [],
      "source": [
        "list(oxides.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld_BFQdbsIAQ"
      },
      "source": [
        "### Description of the dataset\n",
        "\n",
        "In this practical we are attempting to learn a model that can predict the band gap (energy separation between occupied and un-occupied orbitals) of a material. So we need to set this value as the property to be predicted $y$ This data is stored in the dataframe column called `gllbsc_gap` and we set this to be y by running the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IssL3TQxsIAQ"
      },
      "outputs": [],
      "source": [
        "# read a single column\n",
        "y = oxides['gllbsc_gap'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Egm65zGJsIAQ"
      },
      "source": [
        "We can then use the other properties in the dataset, or a combination of them as *features* ($X$) for our model. For example we could set $X$ to be defined by two features by running the cell below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXA6MvLxsIAQ"
      },
      "outputs": [],
      "source": [
        "# read multiple columns and combine them to a matrix\n",
        "X = oxides[['MagpieData minimum MeltingT', 'HOMO_energy']].values\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lT6fkOksIAR"
      },
      "source": [
        "## Regression with the dataset\n",
        "\n",
        "In regression, we attempt to fit a model, $y = f(x)$, where $x$ and $y$ are multi-dimensional data of rank $M$ and $N$, respectively, and $f: \\mathbb{R}^M\\rightarrow\\mathbb{R}^N$ our regression model. In this notebook, $y$ will always be `gllbsc_gap` (so $N=1$), which represents the band gap, and $x$ a combination of the descriptors (all the other columns), each giving the measurement of a certain physical property. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHFZbQsDsIAR"
      },
      "source": [
        "# Linear regression: a starter\n",
        "\n",
        "Linear regression is the simplest regression algorithm in machine learning. Many people do not even regard it as a machine learning algorithm because it is explicitly programmed. Still, it serves as a good start to learn some basic concepts.\n",
        "\n",
        "\n",
        "## Univariate regression\n",
        "\n",
        "In univariate linear regression we have the equation:\n",
        "$y = mx + c$\n",
        "and we are attempting to find the best values for $m$ and $c$\n",
        "\n",
        "In a univariate regression, the input rank $M=1$. For instance, let us try `MagpieData avg_dev Electronegativity` as $x$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_K733Rv-sIAR"
      },
      "outputs": [],
      "source": [
        "# read X\n",
        "X = oxides['MagpieData avg_dev Electronegativity'].values\n",
        "# we need to append a dummy dimension to X for univariate regression\n",
        "# to keep the input dimensions consistent with multivariate regression\n",
        "X = X.reshape(-1, 1)\n",
        "# read y\n",
        "y = oxides['gllbsc_gap'].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lc2ylQH2sIAR"
      },
      "source": [
        "Now we can use linear regression to fit the data and make predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B2w3Rj7KsIAS"
      },
      "outputs": [],
      "source": [
        "# fit linear regression model\n",
        "model = LinearRegression().fit(X, y)\n",
        "# make predictions\n",
        "y_pred = model.predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXC15n-9sIAS"
      },
      "source": [
        "When we have fitted the model we now want to use some *metrics* to *evaluate* the model performance. Remember the mean squared error and mean absolute error from your lectures. We will now calculate them for the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wh5JR-lfsIAS"
      },
      "outputs": [],
      "source": [
        "# compute some fitting error\n",
        "print('MSE = %f eV' % metrics.mean_squared_error(y, y_pred))\n",
        "print('MAE = %f eV' % metrics.mean_absolute_error(y, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-F7AMLYXsIAS"
      },
      "source": [
        "We can also plot the predicted versus the real values to get a visual feel for how well the fitting worked."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goXKgjj-sIAS"
      },
      "outputs": [],
      "source": [
        "plt.figure(dpi=100)\n",
        "plt.scatter(y, y_pred)\n",
        "plt.xlabel('Eg True (eV)')\n",
        "plt.ylabel('Eg Predicted (eV)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3l0lZ9KOsIAT"
      },
      "source": [
        "## Exercise \n",
        "\n",
        "By changeing the feature in the $X$ values above try a number of different features (four or five is enough). How does it affect the quality of fitting? Report the feature and the MAE and MSE scores in the table below. *Note* to edit the contets of this cell, simply double click on the cell.\n",
        "\n",
        "| Feature | MAE (eV) | MSE (eV) |\n",
        "|---------|----------|----------|\n",
        "|         |          |          |\n",
        "|         |          |          |\n",
        "|         |          |          |\n",
        "|         |          |          |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jmrYRQ8sIAT"
      },
      "source": [
        "## Multivariate regression\n",
        "\n",
        "In a multivariate regression, the input rank $M>1$. Therefore, we will choose a few descriptor to form $x$. Here we choose three descriptors ($M=3$):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP09-z-rsIAT"
      },
      "outputs": [],
      "source": [
        "# read X\n",
        "X = oxides[['MagpieData avg_dev CovalentRadius', \n",
        "            'MagpieData avg_dev Electronegativity', \n",
        "            'MagpieData maximum NsValence']].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shdDnyTusIAT"
      },
      "source": [
        "And the rest is the same as univariate regression:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8joSDjsJsIAT"
      },
      "outputs": [],
      "source": [
        "# fit linear regression model\n",
        "model = LinearRegression().fit(X, y)\n",
        "\n",
        "# make predictions\n",
        "y_pred = model.predict(X)\n",
        "\n",
        "# compute some fitting error\n",
        "print('MSE = %f' % metrics.mean_squared_error(y, y_pred))\n",
        "print('MAE = %f' % metrics.mean_absolute_error(y, y_pred))\n",
        "\n",
        "# plot the original and predicted data against each other\n",
        "plt.figure(dpi=100)\n",
        "plt.scatter(y, y_pred)\n",
        "plt.xlabel('Eg True (eV)')\n",
        "plt.ylabel('Eg Predicted (eV)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36qN5o_msIAT"
      },
      "source": [
        "## Exercise \n",
        "\n",
        "By changeing the features in the $X$ values above try a number of different feature combinations (again four or five examples is enough, you can try with any number of features in each example that you like). How does it affect the quality of fitting? Report the feature and the MAE and MSE scores in the table below. *Note* to edit the contets of this cell, simply double click on the cell.\n",
        "\n",
        "| Feature | MAE (eV) | MSE (eV) |\n",
        "|---------|----------|----------|\n",
        "|         |          |          |\n",
        "|         |          |          |\n",
        "|         |          |          |\n",
        "|         |          |          |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBnESa0VsIAU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDrFmSCLsIAU"
      },
      "source": [
        "# Gradient Boosting Regression\n",
        "\n",
        "Gradient boosting is a method for building an ensemble of weak learners to constitute a single strong learner. We build a series of decision trees, each subsequent tree taking in information about the residuals (errors) from the previous trees. In principle, the fitting should improve each time a new tree is added. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HhrH6xFsIAU"
      },
      "source": [
        "## 1. Create the regressor\n",
        "\n",
        "In `sklearn`, a gradient boosting regressor is created by\n",
        "\n",
        "```python\n",
        "GradientBoostingRegressor(loss=<str>, max_depth=<int>, learning_rate=<float>,\n",
        "                          min_samples_split=<int>, min_samples_leaf=<int>, \n",
        "                          max_features=<int>, subsample=<float>, n_estimators=<int>)\n",
        "```\n",
        "\n",
        "\n",
        "The hyperparameters we need to set include:\n",
        "\n",
        "* `loss`: a loss function to be minimised. We will use 'lad', which is basically MAE.\n",
        "* `max_depth`: the maximum depth limits the number of nodes in the trees; its best value depends on the interaction of the input variables; we will start with 10 and can tune it later.\n",
        "* `learning_rate`: learning rate shrinks the contribution of each tree; there is a trade-off between learning rate and boosting steps; we will start with 0.015 and can tune it later.\n",
        "* `min_samples_split`: the minimum number of samples required to split an internal node; we will start with 50 and can tune it later.\n",
        "* `min_samples_leaf`: the minimum number of samples required to be at a leaf node; we set this as 1.\n",
        "* `max_features`: the number of features to consider when looking for the best split; we will use the number of features in the data.\n",
        "* `subsample`: the fraction of samples to be used for fitting the individual trees; if smaller than 1.0, this results in Stochastic Gradient Boosting. we will start with 0.9 and can tune it later.\n",
        "* `n_estimators`: the number of boosting steps or decision trees; we will start with 300 and can tune it later.\n",
        "\n",
        "**NOTE**: Simply adding more trees can lead to overfitting. Gradient boosting is quite robust against overfitting, but we will have to look out for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBZqRJmTsIAU"
      },
      "outputs": [],
      "source": [
        "# create the regressor\n",
        "gbr = GradientBoostingRegressor(loss='lad', max_depth=10, learning_rate=0.015,\n",
        "                                min_samples_split=50, min_samples_leaf=1, \n",
        "                                max_features=len(oxides.columns)-1, subsample=0.9, \n",
        "                                n_estimators=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt6GMKAvsIAU"
      },
      "source": [
        "## 2. Fit the regressor\n",
        "\n",
        "First of all we write some code that sets $X$ to be all of the features **except** `gllbsc_gap`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "buFf7s0GsIAU"
      },
      "outputs": [],
      "source": [
        "# combine all the columns into X\n",
        "cols = [a for a in list(oxides.columns) if a not in ['gllbsc_gap']]\n",
        "X = oxides[cols].values\n",
        "print('Shape of X: %s' % str(X.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCuMt-CmsIAV"
      },
      "source": [
        "We then fit the model that we have defined to find $f(X) = y$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qELcfyj9sIAV"
      },
      "outputs": [],
      "source": [
        "# fit the model\n",
        "gbr.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bK5UmkwWsIAV"
      },
      "source": [
        "After fitting the model, we can make predictions and plot them against the original data. The fit has shown a significant improvement over linear regression. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "013z3T0dsIAV"
      },
      "outputs": [],
      "source": [
        "# make predictions\n",
        "y_pred = gbr.predict(X)\n",
        "\n",
        "# plot the original and predicted data against each other\n",
        "plt.figure(dpi=100)\n",
        "plt.scatter(y, y_pred)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QQFAalzsIAW"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Calcuate the mean absolute error and the mean squared error for the plot above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80k1hoeysIAW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQO_IuAPsIAW"
      },
      "source": [
        "## 3. Cross validation\n",
        "\n",
        "Cross-validation (CV) allows us to evaluate the out-of-sample goodness-of-fit of the regressor without sparing a validation set. In the basic approach, called the k-fold CV, the training set is split into $k$ subsets, each serving as the validation set to evaluate the model trained with the other $k-1$ subsets. This approach can be computationally expensive but does not waste too much data (as is the case when fixing an arbitrary validation set), which is a major advantage for problems with limited data.\n",
        "\n",
        "In the following cell, we compute the scores using 5 folds (so 20% of data for each validation) and the negative MAE as the metric:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l3cgj_HXsIAW"
      },
      "outputs": [],
      "source": [
        "# compute cross validation score\n",
        "scores = cross_val_score(gbr, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
        "print('Cross validation score: {}'.format(-1 * np.mean(scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcS83OGBsIAW"
      },
      "source": [
        "## 4. Boosting rate and overfitting\n",
        "\n",
        "Let us split the dataset 80:20 into training and test sets.  We can use the `train_test_split` function from `scikit-learn` to do this.\n",
        "\n",
        "Re-fit the model using the training set only. \n",
        "\n",
        "We can then use some built-in methods of `GradientBoostingRegressor` to get training and test scores at each iteration of boosting. This way, we can check if we have insufficient boosting layers or perhaps we have too many and thus suffer overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVTmlMKwsIAW"
      },
      "outputs": [],
      "source": [
        "# split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# fit with training set\n",
        "gbr.fit(X_train, y_train)\n",
        "\n",
        "# compute test score at each boosting step\n",
        "test_score = np.zeros((300,), dtype=np.float64)\n",
        "for i, y_pred in enumerate(gbr.staged_predict(X_test)):\n",
        "    test_score[i] = gbr.loss_(y_test, y_pred)\n",
        "\n",
        "# plot the scores\n",
        "plt.figure(dpi=100)\n",
        "plt.plot(gbr.train_score_, label='Loss on training set')\n",
        "plt.plot(test_score, label='Loss on test set')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yPRVSO7sIAW"
      },
      "source": [
        "Notice that the loss of both training and test are still decreasing at 300 steps. We can try to increase the boosting steps to 500 and see if we can still get improvements. If the test score stops increasing, we are probably in a good place to stop extending the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF5w1DPdsIAX"
      },
      "outputs": [],
      "source": [
        "# create the regressor with more boosting steps\n",
        "gbr500 = GradientBoostingRegressor(loss='lad', max_depth=10, learning_rate=0.015,\n",
        "                                   min_samples_split=50, min_samples_leaf=1, \n",
        "                                   max_features=len(oxides.columns)-1, subsample=0.9, \n",
        "                                   n_estimators=500)\n",
        "\n",
        "# fit with training set\n",
        "gbr500.fit(X_train, y_train)\n",
        "\n",
        "# compute test score at each boosting step\n",
        "test_score = np.zeros((500,), dtype=np.float64)\n",
        "for i, y_pred in enumerate(gbr500.staged_predict(X_test)):\n",
        "    test_score[i] = gbr500.loss_(y_test, y_pred)\n",
        "\n",
        "# plot the scores\n",
        "plt.figure(dpi=100)\n",
        "plt.plot(gbr500.train_score_, label='Loss on training set')\n",
        "plt.plot(test_score, label='Loss on test set')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6jF_3jmsIAX"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Repeat the procedure above, but this time try to run up to 1000 boosting steps.\n",
        "\n",
        "**Hint**\n",
        "<details>\n",
        "You need to copy the code above, but reset:\n",
        "    \n",
        "    * n_estimators\n",
        "    \n",
        "    * the size of test_score = np.zeros((500,), dtype=np.float64)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXMimFw8sIAX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogqXAXXmsIAX"
      },
      "source": [
        "Again, do a 5-fold cross validation at this point. How does the score compare to the earlier one?\n",
        "\n",
        "**Hint**\n",
        "<details>\n",
        "    \n",
        "```\n",
        " # compute cross validation score\n",
        "scores = cross_val_score(gbr500, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
        "print('Cross validation score: {}'.format(-1 * np.mean(scores)))\n",
        "```\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HC0Xt9SWsIAX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7g0RkoCsIAX"
      },
      "source": [
        "##  5. Systematic hyperparameter tuning\n",
        "\n",
        "Hand tuning a large number of hyperparameters is laborious. Luckily, `sklearn` provides a function [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to automate searches in the hyperparameter space. Even though, performing a grid-search of all of the hyperparameters at once would again lead to a combinatorial explosion. A general strategy for tuning hyperparameters in gradient boosted trees has been suggested [here](https://www.analyticsvidhya.com/blog/2016/02/complete-guide-parameter-tuning-gradient-boosting-gbm-python/). \n",
        "\n",
        "1. Choose a relatively high learning rate. Generally the default value of 0.1 works but somewhere between 0.05 to 0.2 should work for different problems.\n",
        "2. Determine the optimum number of trees for this learning rate. This should range around 40 to 90. Remember to choose a value on which your system can work fairly fast. This is because it will be used for testing various scenarios and determining the tree parameters.\n",
        "3. Tune tree-specific parameters for decided learning rate and number of trees. \n",
        "4. Lower the learning rate and increase the estimators proportionally to get more robust models.\n",
        "\n",
        "We will follow the above process to tune our regressor.\n",
        "\n",
        "\n",
        "### Step 1 & 2: Optimise `n_estimators` with `learning_rate=0.1`\n",
        "\n",
        "In the cell below we search between 40 and 90 estimators in steps of 10.\n",
        "\n",
        "We then define our model `gbr_n_est`\n",
        "\n",
        "We then define the grid search `gsearch`\n",
        "\n",
        "Finally we tell the grid search to run with `fit`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QMqQ-fDpsIAX"
      },
      "outputs": [],
      "source": [
        "# candidates\n",
        "param_test_n_est = {'n_estimators': range(40, 90, 10)}\n",
        "\n",
        "# create the regressor\n",
        "gbr_n_est = GradientBoostingRegressor(loss='lad', learning_rate=0.1, \n",
        "                                      max_features=len(cols), max_depth=10,\n",
        "                                      min_samples_split=50, subsample=0.9,\n",
        "                                      random_state=0)\n",
        "\n",
        "# define hyperparameter search\n",
        "gsearch = GridSearchCV(estimator= gbr_n_est, param_grid = param_test_n_est, \n",
        "                       scoring='neg_median_absolute_error', cv=5)\n",
        "\n",
        "# perform search\n",
        "gsearch.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjSZMfiTsIAY"
      },
      "source": [
        "### Find the best values\n",
        "\n",
        "We can get the values of the best model from our defined range, in this case we have only `n_estimators` to examine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MfziK3elsIAY"
      },
      "outputs": [],
      "source": [
        "# print best n_estimators\n",
        "gsearch.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwqOefSEsIAY"
      },
      "source": [
        "### Step 3: Optimise tree parameters with best `n_estimators`\n",
        "\n",
        "Here we consider `max_depth` and `min_samples_split`:\n",
        "\n",
        "For depth we search between 5 and 16 in steps of 2.\n",
        "For min samples split we search between 10 and 100 in steps of 20\n",
        "\n",
        "* Question - how many models in total does this result in?\n",
        "\n",
        "**Answer**\n",
        "<details>\n",
        " \n",
        "6 steps for depts $\\times$ 5 steps for split $=$ 30 models\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QbsoYSrsIAY"
      },
      "outputs": [],
      "source": [
        "# candidates\n",
        "param_test_tree = {'max_depth': range(5, 16, 2), \n",
        "                   'min_samples_split': range(10, 100, 20)}\n",
        "\n",
        "# create the regressor\n",
        "gbr_tree = GradientBoostingRegressor(loss='lad', learning_rate=0.1, \n",
        "                                     max_features=len(cols), subsample=0.9,\n",
        "                                     n_estimators=<insert value>, random_state=0)\n",
        "\n",
        "# define hyperparameter search\n",
        "gsearch = GridSearchCV(estimator= gbr_tree, param_grid = param_test_tree, \n",
        "                       scoring='neg_median_absolute_error', cv=5)\n",
        "\n",
        "# perform search\n",
        "gsearch.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kCROfPDsIAY"
      },
      "source": [
        "### Exercise\n",
        "\n",
        "Find the best values, using similar code to the previous time\n",
        "\n",
        "**Hint**\n",
        "\n",
        "<details>\n",
        "\n",
        "```\n",
        "gsearch.best_params_\n",
        "```\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MSqQSYxNsIAY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STxcN_FXsIAY"
      },
      "source": [
        "### Step 4: Lower `learning_rate` and increase `n_estimators`\n",
        "\n",
        "Here we use a factor of 5, so `learning_rate` is lowered to 0.2 and `n_estimators` increased to 350:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sKXZPzSGsIAZ"
      },
      "outputs": [],
      "source": [
        "# create the \"optimised\" regressor\n",
        "gbr_opt = GradientBoostingRegressor(loss='lad', learning_rate=0.2, \n",
        "                                    max_features=len(cols), max_depth=<insert value>,\n",
        "                                    min_samples_split=<insert value>, subsample=0.9,\n",
        "                                    n_estimators=350, random_state=0)\n",
        "\n",
        "# fit the model\n",
        "gbr_opt.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmTBR1XmsIAZ"
      },
      "source": [
        "Eventually, we can use our \"optimised\" model to make predictions and compute CV scores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWGRXLF8sIAZ"
      },
      "outputs": [],
      "source": [
        "# make predictions\n",
        "y_pred = gbr_opt.predict(X)\n",
        "\n",
        "# plot the original and predicted data against each other\n",
        "plt.figure(dpi=100)\n",
        "plt.scatter(y, y_pred)\n",
        "plt.show()\n",
        "\n",
        "# compute cross validation score\n",
        "scores = cross_val_score(gbr_opt, X, y, cv=5, scoring='neg_mean_absolute_error')\n",
        "print('Cross validation score: {}'.format(-1 * np.mean(scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3mpo_H_sIAZ"
      },
      "source": [
        "**Yes, our efforts pay off**, as shown by the figure and the CV score!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-26dUeHsIAZ"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYTNeh_2sIAZ"
      },
      "source": [
        "## Feature importance\n",
        "\n",
        "We can look at how much a certain feature contributes to the model by looking at `gbr_opt.feature_importances_`\n",
        "\n",
        "In the cell below we plot the feature importances on a bar chart, hopefully you see that importance drops off quite quickly and some features have little contribution to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yM4LVMisIAZ"
      },
      "outputs": [],
      "source": [
        "importances = gbr_opt.feature_importances_\n",
        "\n",
        "indices = np.argsort(importances)[::-1]\n",
        "\n",
        "# Plot the impurity-based feature importances of the forest\n",
        "fig, ax = plt.subplots(1, figsize=(12,6))\n",
        "\n",
        "ax.set_title(\"Feature importances\")\n",
        "ax.bar(range(X.shape[1]), importances[indices],\n",
        "        color=\"r\", align=\"center\")\n",
        "#plt.xticks(range(X.shape[1]), indices)\n",
        "plt.xlim([-1, 100])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8ixewnpsIAa"
      },
      "source": [
        "We can also list the features in order of importance and see which features contribute most to the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jAmBaJ_5sIAa"
      },
      "outputs": [],
      "source": [
        "# Print the feature ranking\n",
        "print(\"Feature ranking:\")\n",
        "\n",
        "for f in range(X.shape[1]):\n",
        "   print(\"%d. %s (%f)\" % (f + 1, cols[indices[f]], importances[indices[f]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MycRQFdsIAa"
      },
      "source": [
        "## Exercises \n",
        "\n",
        "It is often desrireable to fit a model using fewer features as this protects against overfitting and also gives models that are easier to interpret. Using the information above build a gradient boosted decision tree, but use **only** the top fifty most important features from the old model. What kind of validation accuracy can you achieve?\n",
        "\n",
        "**Hint 1**\n",
        "\n",
        "<details>\n",
        "    \n",
        "To build a new X with just the top 50 features you can use code like below.\n",
        "    \n",
        "**Note** be sure to call this a new name so that you do not overwrite X\n",
        "    \n",
        "```\n",
        "xtops = [cols[i] for i in indices[:50]]\n",
        "# combine all the columns into Xs\n",
        "Xs = oxides[xtops].values  \n",
        "    \n",
        "```\n",
        "    \n",
        "</details>\n",
        "\n",
        "**Hint 2**\n",
        "<details>\n",
        "    \n",
        "Remember when setting up your `GradientBoostingRegressor` that the `max_features` should now be set to 50\n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JxKqVuaWsIAa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiAuV3H0sIAa"
      },
      "source": [
        "When you have built the model and fitted it, use the cross-validation routine from above to check how well it works.\n",
        "\n",
        "**Hint**\n",
        "\n",
        "<details>\n",
        " \n",
        "Make sure that you are feeding the correct model and X and y data to the `cross_val_score` function.\n",
        "It should get the model that you have just defined and the X data you defined just about too, **not** the X data from the earlier fitting. \n",
        "    \n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzYgutrtsIAa"
      },
      "source": [
        "## Exercise\n",
        "\n",
        "Do the hyperparameter tuning as detailed above and see how good you can make this smaller model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYw9izpQsIAa"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "regression_decision_tree_practical.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}